name: Sync RBL to Cortex XDR (best-effort)

on:
  push:
    paths:
      - 'fqdnlist.txt'
      - 'iplist.txt'
      - 'hashlist.txt'
      - '.github/workflows/xdr-ioc-sync.yml'
  workflow_dispatch: {}

jobs:
  sync:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # ---------- IOC upload (never fail the job) ----------
      - name: Push IOCs to Cortex XDR (best-effort)
        continue-on-error: true
        env:
          XDR_BASE_URL: ${{ secrets.XDR_BASE_URL }}
          XDR_API_ID:   ${{ secrets.XDR_API_ID }}
          XDR_API_KEY:  ${{ secrets.XDR_API_KEY }}
          VENDOR:       ONO-RBL
          COMMENT_TAG:  GitHub sync test
        run: |
          # Your repo script does parsing + insert_jsons; let the job continue even on errors.
          python xdr_ioc_upsert_from_sources.py || echo "[warn] uploader failed but continuing (best-effort)"

      - name: Upload rejects (if any)
        uses: actions/upload-artifact@v4
        with:
          name: xdr-rejects
          path: rejects.json
          if-no-files-found: ignore

      # ---------- Canary insert + tolerant verification ----------
      - name: Insert canary IOC & try to verify (best-effort)
        id: canary
        continue-on-error: true
        env:
          XDR_BASE_URL: ${{ secrets.XDR_BASE_URL }}
          XDR_API_ID:   ${{ secrets.XDR_API_ID }}
          XDR_API_KEY:  ${{ secrets.XDR_API_KEY }}
          VENDOR:       ONO-RBL
          COMMENT_TAG:  "GitHub sync test"
        run: |
          python - <<'PY'
          import os, sys, time, json, requests
          from datetime import datetime, timezone

          BASE   = os.environ["XDR_BASE_URL"].rstrip("/")
          API_ID = os.environ["XDR_API_ID"]
          APIKEY = os.environ["XDR_API_KEY"]
          VENDOR = os.getenv("VENDOR","ONO-RBL")
          COMMENT= os.getenv("COMMENT_TAG","GitHub sync test")

          H = {
            "Authorization": APIKEY,
            "x-xdr-auth-id": API_ID,
            "Content-Type": "application/json",
            "Accept": "application/json"
          }

          def post(uri, payload, max_retries=6, timeout=120):
            backoff=2
            for attempt in range(1, max_retries+1):
              try:
                r = requests.post(uri, headers=H, json=payload, timeout=timeout)
                # treat infra errors as retryable
                if r.status_code in (429,500,502,503,504,599):
                  ra = r.headers.get("Retry-After")
                  sleep = int(ra) if ra and ra.isdigit() else backoff
                  print(f"[retry] HTTP {r.status_code} sleeping {sleep}s (attempt {attempt}/{max_retries})")
                  time.sleep(sleep); backoff = min(int(backoff*2.2), 90)
                  continue
                r.raise_for_status()
                return r.json()
              except requests.RequestException as e:
                if attempt == max_retries: raise
                print(f"[retry] {e}; backoff {backoff}s")
                time.sleep(backoff); backoff = min(int(backoff*2.2), 90)

          canary = f"ono-rbl-canary-{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S')}.example"
          print(f"[insert] {canary}")

          # Insert via insert_jsons (most reliable cross-tenant)
          ins_uri = f"{BASE}/public_api/v1/indicators/insert_jsons"
          ins_body = {"request_data":{"indicators":[{
            "indicator": canary,
            "type": "DOMAIN_NAME",
            "severity": "MEDIUM",
            "reputation": "BAD",
            "comment": COMMENT,
            "vendor": {"name": VENDOR}
          }]}}
          try:
            js = post(ins_uri, ins_body)
            print(js)
          except Exception as e:
            # insert could still succeed server-side; we continue best-effort
            print(f"[warn] insert_jsons call errored: {e}")

          # Best-effort verification (do not fail job)
          ok = False
          get_uri = f"{BASE}/public_api/v1/indicators/get"
          for i in range(12):  # ~2 minutes
            try:
              q = {"request_data":{
                "search_from":0, "search_to":50,
                "filters":[{"field":"indicator","operator":"eq","value":canary}]
              }}
              resp = post(get_uri, q, max_retries=3, timeout=90)
              items = (resp or {}).get("reply",{}).get("indicators",[]) or []
              if any(it.get("indicator")==canary for it in items):
                ok = True; break
            except Exception as e:
              print(f"[verify] {e}")
            time.sleep(10)

          status = "visible" if ok else "inconclusive"
          with open("canary.txt","w") as f:
            f.write(canary+"\n"+status+"\n")
          print(f"CANARY={canary}\nCANARY_STATUS={status}")
          PY

      - name: Save canary details (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: xdr-canary
          path: canary.txt
          if-no-files-found: warn

      - name: Summarize
        shell: bash
        run: |
          echo "### Canary result" >> $GITHUB_STEP_SUMMARY
          if [[ -f canary.txt ]]; then
            CANARY=$(sed -n '1p' canary.txt)
            STATUS=$(sed -n '2p' canary.txt)
            echo "- **Indicator**: \`$CANARY\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Status**: \`$STATUS\`" >> $GITHUB_STEP_SUMMARY
            if [[ "$STATUS" != "visible" ]]; then
              echo "> Listing API returned 5xx/599 from the runner. Inserts likely succeeded; confirm locally or via Audit logs." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- No canary file produced." >> $GITHUB_STEP_SUMMARY
          fi
